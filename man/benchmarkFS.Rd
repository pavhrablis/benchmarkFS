% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/main.R
\name{benchmarkFS}
\alias{benchmarkFS}
\title{Run end-to-end Benchmark for comparison of feature selection methods.}
\usage{
benchmarkFS(
  x,
  y,
  methods = c("fs.utest"),
  method.cv = "kfoldcv",
  params.cv = list(k = 3, iter = 5, test.size = 0.3),
  level.cor = 1,
  params = list(adjust = "holm", feature.number = 10),
  asm = c("fs.utest"),
  model = c("fs.utest")
)
}
\arguments{
\item{x}{input data where columns are variables and rows are observations (all numeric)}

\item{y}{decision variable as a boolean vector of length equal to number of observations}

\item{methods}{A \code{\link{vector}}  with feature selection methods available in this library for comparison}

\item{method.cv}{validation method \code{kfoldcv} for cross-validation \code{k-fold} or \code{rsampling} for \code{random sampling} or \code{loocv} for leave-one-out cross-validation}

\item{params.cv}{A \code{\link{list}} with the following fields:
\itemize{
\item \code{k} --  the number of groups that a given data sample is to be split into, not less than 3
\item \code{test.size} -- testing set size for random sampling validation
\item \code{iter} -- the number of validation repetitions
}}

\item{level.cor}{cutoff level of correlated variables. If equal to 1 is not performed}

\item{params}{A \code{\link{list}} with the following fields:
\itemize{
\item \code{adjust} -- method as accepted by \code{\link[stats]{p.adjust}} (\code{"BY"} is recommended for FDR, see Details) or \code{\link[sgof]{SGoF}} for MDFS1D, MDFS2D and U-test
\item \code{mrmr.feature.number} -- number of attributes to select. Must not exceed \code{ncol(x)}
}}

\item{asm}{A \code{\link{vector}} with enumeration method for which to calculate Lustgartenâ€™s stability measure}

\item{model}{A \code{\link{vector}} with enumeration method for which to training and testing model \code{RandomForest}}
}
\value{
\itemize{
\item \code{selected.feature} -- A \code{\link{list}} with the result of feature selection for the selected feature selection method
\item \code{ranking.feature} -- A \code{\link{list}} with the result of the rating of the variables that were most often performed in each iteration of cross-validation
\item \code{stability} -- A \code{\link{data.frame}} with the result of stability of selection of feature for the selected selection method
\item \code{model} -- A \code{\link{data.frame}} with the result of constructing a random forest model for the selected feature selection method
}
}
\description{
Run end-to-end Benchmark for comparison of feature selection methods.
}
\details{
Benchmark for comparison of feature selection methods dedicated to high-throughput
sequencing data.
}
\examples{
\dontest{

decisions <- data$class
data$class <- NULL

benchmarkFS(data,
           decisions,
           methods = c('fs.utest', 'fs.mrmr'),
           method.cv = 'cv.kfold',
           params.cv = list(k = 3, iter = 10),
           level.cor = 0.75,
           params = list(adjust = 'SGoF', mrmr.feature.number = 10),
           asm = c('fs.utest', 'fs.mrmr'),
           model = c('fs.utest', 'fs.mrmr')
           )

}

}
